{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRvBmzB+086RM6Oe81EBzp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newmantic/GMM/blob/main/GMM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct7bzhaAis97",
        "outputId": "7731880b-84a7-4bcd-f182-db7372f3a0ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted probabilities:\n",
            "[[1.00000000e+00 8.27754248e-31]\n",
            " [1.00000000e+00 1.90789939e-31]\n",
            " [1.00000000e+00 2.36820330e-24]\n",
            " [1.00000000e+00 5.73742631e-41]\n",
            " [1.00000000e+00 3.67151367e-22]]\n",
            "Generated samples:\n",
            "[[4.51245428 4.08656052]\n",
            " [6.44138583 4.24201068]\n",
            " [4.57495362 6.78040247]\n",
            " [5.56375616 4.28671721]\n",
            " [5.57079248 6.3388876 ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "class GaussianMixtureModel:\n",
        "    def __init__(self, n_components, max_iter=100, tol=1e-6):\n",
        "        \"\"\"\n",
        "        Initialize the GMM with the number of components and other parameters.\n",
        "\n",
        "        Parameters:\n",
        "        n_components (int): Number of Gaussian components in the mixture.\n",
        "        max_iter (int): Maximum number of iterations for the EM algorithm.\n",
        "        tol (float): Convergence threshold for the log-likelihood.\n",
        "        \"\"\"\n",
        "        self.n_components = n_components\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Fit the GMM to the data using the EM algorithm.\n",
        "\n",
        "        Parameters:\n",
        "        X (np.ndarray): Data matrix of shape (n_samples, n_features).\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize the parameters\n",
        "        self.weights = np.full(self.n_components, 1 / self.n_components)\n",
        "        self.means = np.random.rand(self.n_components, n_features)\n",
        "        self.covariances = np.array([np.eye(n_features)] * self.n_components)\n",
        "        log_likelihood_prev = None\n",
        "\n",
        "        for iteration in range(self.max_iter):\n",
        "            # E-step: Compute responsibilities\n",
        "            responsibilities = np.zeros((n_samples, self.n_components))\n",
        "            for k in range(self.n_components):\n",
        "                responsibilities[:, k] = self.weights[k] * multivariate_normal(self.means[k], self.covariances[k]).pdf(X)\n",
        "            responsibilities /= responsibilities.sum(axis=1, keepdims=True)\n",
        "\n",
        "            # M-step: Update the parameters\n",
        "            Nk = responsibilities.sum(axis=0)\n",
        "            self.weights = Nk / n_samples\n",
        "            self.means = np.dot(responsibilities.T, X) / Nk[:, np.newaxis]\n",
        "            for k in range(self.n_components):\n",
        "                X_centered = X - self.means[k]\n",
        "                self.covariances[k] = np.dot(responsibilities[:, k] * X_centered.T, X_centered) / Nk[k]\n",
        "\n",
        "            # Compute the log-likelihood\n",
        "            log_likelihood = np.sum(np.log(np.sum([\n",
        "                self.weights[k] * multivariate_normal(self.means[k], self.covariances[k]).pdf(X)\n",
        "                for k in range(self.n_components)\n",
        "            ], axis=0)))\n",
        "\n",
        "            # Check for convergence\n",
        "            if log_likelihood_prev is not None and abs(log_likelihood - log_likelihood_prev) < self.tol:\n",
        "                break\n",
        "            log_likelihood_prev = log_likelihood\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predict the probabilities of each sample in X belonging to each component.\n",
        "\n",
        "        Parameters:\n",
        "        X (np.ndarray): Data matrix of shape (n_samples, n_features).\n",
        "\n",
        "        Returns:\n",
        "        np.ndarray: Probability matrix of shape (n_samples, n_components).\n",
        "        \"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        probabilities = np.zeros((n_samples, self.n_components))\n",
        "        for k in range(self.n_components):\n",
        "            probabilities[:, k] = self.weights[k] * multivariate_normal(self.means[k], self.covariances[k]).pdf(X)\n",
        "        probabilities /= probabilities.sum(axis=1, keepdims=True)\n",
        "        return probabilities\n",
        "\n",
        "    def sample(self, n_samples):\n",
        "        \"\"\"\n",
        "        Sample new data points from the fitted GMM.\n",
        "\n",
        "        Parameters:\n",
        "        n_samples (int): Number of samples to generate.\n",
        "\n",
        "        Returns:\n",
        "        np.ndarray: Generated data of shape (n_samples, n_features).\n",
        "        \"\"\"\n",
        "        samples = []\n",
        "        component_choices = np.random.choice(self.n_components, size=n_samples, p=self.weights)\n",
        "        for k in component_choices:\n",
        "            samples.append(np.random.multivariate_normal(self.means[k], self.covariances[k]))\n",
        "        return np.array(samples)\n",
        "\n",
        "# Testable example:\n",
        "# Generate some synthetic data\n",
        "np.random.seed(42)\n",
        "X = np.vstack([\n",
        "    np.random.multivariate_normal([0, 0], [[1, 0.5], [0.5, 1]], 100),\n",
        "    np.random.multivariate_normal([5, 5], [[1, -0.5], [-0.5, 1]], 100)\n",
        "])\n",
        "\n",
        "# Fit the GMM\n",
        "gmm = GaussianMixtureModel(n_components=2)\n",
        "gmm.fit(X)\n",
        "\n",
        "# Predict probabilities for the data points\n",
        "probabilities = gmm.predict_proba(X)\n",
        "print(f\"Predicted probabilities:\\n{probabilities[:5]}\")\n",
        "\n",
        "# Sample new data points from the GMM\n",
        "samples = gmm.sample(5)\n",
        "print(f\"Generated samples:\\n{samples}\")"
      ]
    }
  ]
}